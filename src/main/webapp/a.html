<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Title</title>
</head>
<body>
<video autoplay id="sourcevid" style="width:480px;height:320px"></video>
<canvas id="output" style="display:none"></canvas>
</body>
<script type="text/javascript" charset="utf-8">
    //创建一个+实例
    var socket = new WebSocket("ws://172.16.18.13:8080/websocket");
    var back = document.getElementById('output');
    //返回一个用于在画布上绘图的环境。
    var backcontext = back.getContext('2d');
    var video = document.getElementsByTagName('video')[0];
    var success = function(stream){
        //获取视屏流，转换为url
        // video.src = window.URL.createObjectURL(stream);
        video.srcObject = stream;
    }
    //打开socket
    socket.onopen = function(){
        draw();
        console.log("open success")
    }
    // 将视频帧绘制到Canvas对象上,Canvas每100ms切换帧，形成肉眼视频效果
    var draw = function(){
        try{
            backcontext.drawImage(video,0,0, back.width, back.height);
        }catch(e){
            if (e.name == "NS_ERROR_NOT_AVAILABLE") {
                return setTimeout(draw, 100);
            } else {
                throw e;
            }
        }
        if(video.srcObject){
            // Canvas的内容转化成PNG data URI并发送到服务器，0.5为和压缩系数
            console.log("发消息吗")
            socket.send(back.toDataURL("image/jpeg", 0.5));
        }
        console.log("没有执行吗")
        setTimeout(draw, 100);
    }
    //调用设备的摄像头,并将资源放入video标签
    navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia ||
        navigator.mozGetUserMedia || navigator.msGetUserMedia;
    navigator.getUserMedia({video:true, audio:false}, success, console.log);
</script>

</html>
